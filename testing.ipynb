{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2363e6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "from typing import List, Dict, Any, TypedDict, Tuple # Added Tuple\n",
    "import json # Ensure json is imported\n",
    "import re # Ensure re is imported\n",
    "\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langgraph.graph import StateGraph, END\n",
    "import faiss\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load a pre-trained model\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "os.environ[\"GOOGLE_API_KEY\"] = 'AIzaSyDlo-rq9YxnUs4r5sJEHlgMw1dgs5TAd08' # Replace with your key or use environment variables\n",
    "\n",
    "# --- Load data (ensure paths are correct) ---\n",
    "try:\n",
    "    index = faiss.read_index('product_embeddings.faiss')\n",
    "    comprehensive_product_profiles_df = pd.read_csv('comprehensive_product_profiles.csv')\n",
    "\n",
    "    tag_set = set()\n",
    "    if 'tags' in comprehensive_product_profiles_df.columns and comprehensive_product_profiles_df.tags.notna().any():\n",
    "        for tags_entry in comprehensive_product_profiles_df.tags.dropna().str.split('|'):\n",
    "            tag_set.update(tags_entry)\n",
    "    else:\n",
    "        print(\"Warning: 'tags' column missing or empty in comprehensive_product_profiles.csv. Tags functionality will be limited.\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error loading data files: {e}. Please ensure '../product_embeddings.faiss' and '../comprehensive_product_profiles.csv' exist.\")\n",
    "    # Depending on the desired behavior, you might want to exit or run with limited functionality.\n",
    "    # For now, we'll let it potentially fail later if these are crucial and not found.\n",
    "    index = None\n",
    "    comprehensive_product_profiles_df = pd.DataFrame() # Empty DataFrame\n",
    "    tag_set = set()\n",
    "\n",
    "\n",
    "# --- State Definition with Chat History ---\n",
    "class PersonalShopperState(TypedDict):\n",
    "    input: str  # User's original query\n",
    "    chat_history: List[Dict[str, str]] | None # e.g. [{\"role\": \"user\", \"content\": \"...\"}, {\"role\": \"assistant\", \"content\": \"...\"}]\n",
    "    input_type: str | None  # 'keyword', 'vague', 'good', or 'informational'\n",
    "    clarification_questions: List[str] | None # Questions to ask the user\n",
    "    clarification_answers: Dict[str, str] | None # User's answers to questions (used if user provides answers later)\n",
    "    recommended_products: List[Dict[str, Any]] | None # List of recommended products\n",
    "    follow_up_question: str | None # Question to ask after recommendations for keyword inputs\n",
    "    informational_answer: str | None\n",
    "    identified_categories: List[str] | None\n",
    "    identified_tags: List[str] | None\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash-latest\", temperature=0)\n",
    "\n",
    "# --- Helper function to format chat history ---\n",
    "def format_chat_history_for_prompt(chat_history: List[Dict[str, str]] | None) -> str:\n",
    "    if not chat_history or len(chat_history) <= 1: # Don't show history if it's just the current user query\n",
    "        return \"No significant prior conversation history.\"\n",
    "    \n",
    "    # Display all but the last message (which is the current user input already in 'input_text')\n",
    "    history_to_display = chat_history[:-1] if chat_history else []\n",
    "    if not history_to_display:\n",
    "        return \"No significant prior conversation history.\"\n",
    "\n",
    "    history_str = \"Conversation History:\\n\"\n",
    "    for entry in history_to_display:\n",
    "        history_str += f\"{entry['role'].capitalize()}: {entry['content']}\\n\"\n",
    "    return history_str.strip()\n",
    "\n",
    "# --- Node Functions (Updated for Chat History) ---\n",
    "\n",
    "def identify_categories_and_tags_json(state: PersonalShopperState) -> PersonalShopperState:\n",
    "    print(f\"Identifying categories and tags for input: {state['input']}\")\n",
    "    input_text = state['input']\n",
    "    chat_history_str = format_chat_history_for_prompt(state.get('chat_history'))\n",
    "\n",
    "    available_categories = []\n",
    "    if 'category' in comprehensive_product_profiles_df.columns:\n",
    "        available_categories = comprehensive_product_profiles_df.category.unique().tolist()\n",
    "    available_tags = list(tag_set)\n",
    "\n",
    "    prompt = f\"\"\"{chat_history_str}\n",
    "\n",
    "You are a helpful assistant that identifies potential skincare product categories and tags from the LATEST user's query, considering the conversation history for context.\n",
    "Based on the LATEST query, list the most likely relevant categories and tags *ONLY* from the following provided lists.\n",
    "\n",
    "Available Categories: {', '.join(available_categories) if available_categories else \"N/A\"}\n",
    "Available Tags: {', '.join(available_tags) if available_tags else \"N/A\"}\n",
    "\n",
    "Respond with a JSON object containing two keys: \"categories\" and \"tags\". Each key should have a list of strings.\n",
    "If no relevant categories or tags from the provided lists are identified for a key, the list should be empty.\n",
    "\n",
    "Example JSON output if the user asks for \"hydrating serum for oily skin\":\n",
    "{{\n",
    "  \"categories\": [\"Serum\"],\n",
    "  \"tags\": [\"Hydration\", \"oily-skin\"]\n",
    "}}\n",
    "\n",
    "LATEST User Query: \"{input_text}\"\n",
    "\n",
    "JSON Output:\n",
    "\"\"\"\n",
    "    new_state = state.copy()\n",
    "    new_state.update({\n",
    "        'recommended_products': None, 'follow_up_question': None,\n",
    "        'informational_answer': None, 'clarification_questions': None,\n",
    "        'identified_categories': None, 'identified_tags': None\n",
    "    })\n",
    "\n",
    "    try:\n",
    "        response = llm.invoke(prompt)\n",
    "        json_output_str = response.content.strip()\n",
    "        # Robust JSON extraction\n",
    "        try:\n",
    "            # Try to find the JSON block if markdown is used\n",
    "            match = re.search(r\"```json\\s*([\\s\\S]*?)\\s*```\", json_output_str)\n",
    "            if match:\n",
    "                json_data_str = match.group(1)\n",
    "            else: # Assume raw JSON or cleanup if LLM doesn't use markdown\n",
    "                json_data_str = json_output_str[json_output_str.find('{'):json_output_str.rfind('}')+1]\n",
    "\n",
    "            identified_terms_json = json.loads(json_data_str)\n",
    "            categories = identified_terms_json.get('categories', [])\n",
    "            tags = identified_terms_json.get('tags', [])\n",
    "\n",
    "            filtered_categories = [cat.strip() for cat in categories if cat.strip() in available_categories]\n",
    "            filtered_tags = [tag.strip() for tag in tags if tag.strip() in available_tags]\n",
    "\n",
    "            new_state['identified_categories'] = filtered_categories if filtered_categories else None\n",
    "            new_state['identified_tags'] = filtered_tags if filtered_tags else None\n",
    "\n",
    "            print(f\"Identified categories: {new_state['identified_categories']}\")\n",
    "            print(f\"Identified tags: {new_state['identified_tags']}\")\n",
    "\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"LLM returned invalid JSON: {json_output_str}.\")\n",
    "        except Exception as e_parse:\n",
    "             print(f\"Error parsing LLM JSON output: {e_parse}. Output: {json_output_str}\")\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during category/tag identification: {e}.\")\n",
    "\n",
    "    return new_state\n",
    "\n",
    "\n",
    "def check_input_type(state: PersonalShopperState) -> PersonalShopperState:\n",
    "    print(f\"Checking input type for: {state['input']} using LLM\")\n",
    "    input_text = state['input']\n",
    "    chat_history_str = format_chat_history_for_prompt(state.get('chat_history'))\n",
    "\n",
    "    # MODIFIED PROMPT STARTS HERE\n",
    "    prompt = f\"\"\"{chat_history_str}\n",
    "\n",
    "You are an expert assistant at classifying user queries in an ongoing conversation. Your task is to classify the LATEST user skincare query (provided at the end) into one of four types: 'keyword', 'vague', 'good', or 'informational'.\n",
    "\n",
    "**Crucially, you MUST analyze the ENTIRE \"Conversation History\" provided above.** This history is vital for understanding the user's current intent, especially if the LATEST query is a response to a question from the assistant or a refinement of a previously discussed topic.\n",
    "\n",
    "Instructions for using conversation history:\n",
    "1.  **Identify Active Context:** Determine if there's an active product category (e.g., \"serum,\" \"moisturizer\") or specific topic being discussed from the recent history.\n",
    "2.  **Check for Answers/Refinements:** If the LATEST User Query seems to be an answer to a question asked by the assistant in the previous turn, or provides a specific detail (like a skin concern or preferred attribute) related to the active context, combine this information.\n",
    "    * Example 1:\n",
    "        * History: Assistant asked, \"What are your main concerns for the serum?\"\n",
    "        * LATEST User Query: \"anti-aging and brightness\"\n",
    "        * Interpretation: The user wants an \"anti-aging and brightening serum.\" This should be classified as 'good'.\n",
    "    * Example 2:\n",
    "        * History: User said, \"I need a moisturizer.\" Assistant recommended some.\n",
    "        * LATEST User Query: \"preferably one for sensitive skin\"\n",
    "        * Interpretation: The user wants a \"moisturizer for sensitive skin.\" This is 'good'.\n",
    "3.  **Standalone Queries:** If the LATEST User Query introduces a completely new topic or doesn't directly relate to the immediate preceding turns, classify it more on its own merits, but still be aware of the overall conversation flow.\n",
    "\n",
    "Definitions of Classification Types (apply after considering history):\n",
    "- 'keyword': The LATEST User Query, possibly contextualized by history, primarily names a specific product category (e.g., \"serum\", \"cleanser\"). Example: \"Let's look at cleansers now.\" or (History: \"We discussed serums.\") LATEST User Query: \"Okay, just a basic one.\" (interpreted as basic serum -> keyword/good).\n",
    "- 'vague': The LATEST User Query, even when considering the conversation history, remains too general, lacks a clear product type, or doesn't provide enough specifics to make a recommendation. Example: User: \"I don't know what I want.\" or User: \"Something else.\" (without further context).\n",
    "- 'good': The LATEST User Query, when combined with necessary context from history, is specific enough to recommend products. It typically implies a product type and one or more attributes/concerns. Example: (History: \"Looking for sunscreen.\") LATEST User Query: \"SPF 50 and good for oily skin.\" (interpreted as \"SPF 50 sunscreen for oily skin\").\n",
    "- 'informational': The LATEST User Query seeks information, advice, or comparison, rather than directly requesting a product type for recommendation. Example: \"What's the difference between retinol and bakuchiol?\" or \"Are those eye creams any good?\".\n",
    "\n",
    "LATEST User Query: \"{input_text}\"\n",
    "\n",
    "Based on your analysis of the conversation history and the LATEST User Query, output ONLY one word corresponding to its classification: 'keyword', 'vague', 'good', or 'informational'.\n",
    "\n",
    "Classification:\"\"\"\n",
    "    # MODIFIED PROMPT ENDS HERE\n",
    "\n",
    "    input_type = 'good' # Default optimistic default\n",
    "    try:\n",
    "        response = llm.invoke(prompt)\n",
    "        classified_type = response.content.strip().lower()\n",
    "        if classified_type in ['keyword', 'vague', 'good', 'informational']:\n",
    "            input_type = classified_type\n",
    "            print(f\"LLM classified input as: {input_type}\")\n",
    "        else:\n",
    "            print(f\"LLM returned unexpected output for input type classification: '{classified_type}'. Defaulting based on rules. Input was: '{input_text}'\")\n",
    "            # Fallback logic: simple rule-based as a backup if LLM fails\n",
    "            if \"how\" in input_text.lower() or \"what\" in input_text.lower() or \"?\" in input_text or \"explain\" in input_text.lower():\n",
    "                input_type = 'informational'\n",
    "            elif any(kw in input_text.lower() for kw in ['serum', 'moisturizer', 'cleanser', 'toner', 'spf', 'mask', 'cream', 'oil', 'lotion']):\n",
    "                # If it contains specific product-related keywords not framed as a question\n",
    "                if len(input_text.split()) > 3 or any(concern_kw in input_text.lower() for concern_kw in ['oily', 'dry', 'sensitive', 'anti-aging', 'acne', 'brightening', 'hydrating']): # Arbitrary threshold for more specific query\n",
    "                    input_type = 'good'\n",
    "                else:\n",
    "                    input_type = 'keyword'\n",
    "            elif len(input_text.split()) < 3 and 'something' in input_text.lower(): # very short and general\n",
    "                 input_type = 'vague'\n",
    "            else: # Default fallback if other rules don't catch it\n",
    "                input_type = 'vague'\n",
    "            print(f\"Fallback classification used: {input_type}\")\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during LLM classification: {e}. Defaulting to 'good'.\")\n",
    "        input_type = 'good' # In case of exception, default might need to be safer, e.g., 'vague'\n",
    "\n",
    "    new_state = state.copy()\n",
    "    new_state['input_type'] = input_type\n",
    "    return new_state\n",
    "\n",
    "\n",
    "def ask_clarification_questions(state: PersonalShopperState) -> PersonalShopperState:\n",
    "    print(\"Generating clarification questions for vague input...\")\n",
    "    input_text = state['input']\n",
    "    chat_history_str = format_chat_history_for_prompt(state.get('chat_history'))\n",
    "\n",
    "    prompt = f\"\"\"{chat_history_str}\n",
    "\n",
    "You are a helpful and friendly salesperson for EverGlow Labs.\n",
    "The customer's LATEST query is: \"{input_text}\". This seems a bit vague, or we need more details based on our conversation.\n",
    "To help them find the perfect product, generate 1-2 concise clarification questions.\n",
    "Focus on understanding their skin type, specific concerns, or preferred product types (like serum, toner, SPF) if not already clear from the history.\n",
    "Present them clearly.\n",
    "\n",
    "Clarification Questions:\n",
    "\"\"\"\n",
    "    questions = []\n",
    "    try:\n",
    "        response = llm.invoke(prompt)\n",
    "        questions = [q.strip() for q in response.content.strip().split('\\n') if q.strip() and q.strip() != \"Clarification Questions:\"]\n",
    "        print(f\"Generated questions: {questions}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating clarification questions: {e}\")\n",
    "        questions = [\"Could you tell me a bit more about your skin concerns or what you're looking for?\"]\n",
    "\n",
    "\n",
    "    new_state = state.copy()\n",
    "    new_state['clarification_questions'] = questions\n",
    "    new_state['recommended_products'] = None\n",
    "    new_state['follow_up_question'] = None\n",
    "    new_state['informational_answer'] = None\n",
    "    return new_state\n",
    "\n",
    "# search_products_with_index remains the same as it doesn't directly use LLM or chat history for its core FAISS logic.\n",
    "def search_products_with_index(query: str, top_k: int = 5) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Searches the FAISS index with the query and returns product details.\n",
    "    Assumes access to comprehensive_product_profiles_df, index, and embedding_model globals.\n",
    "    \"\"\"\n",
    "    print(f\"Searching FAISS index for query: '{query}'\")\n",
    "    # Ensure globals are accessible or passed if this were in a class/different structure\n",
    "    global comprehensive_product_profiles_df, index, embedding_model\n",
    "\n",
    "    if comprehensive_product_profiles_df is None or comprehensive_product_profiles_df.empty or index is None or embedding_model is None:\n",
    "        print(\"Error: FAISS index, embedding model, or product data not available for search.\")\n",
    "        return []\n",
    "\n",
    "    try:\n",
    "        query_embedding = embedding_model.encode(query).astype('float32')\n",
    "        distances, indices_faiss = index.search(query_embedding.reshape(1, -1), top_k)\n",
    "        result_indices = indices_faiss[0]\n",
    "\n",
    "        valid_indices = [idx for idx in result_indices if idx < len(comprehensive_product_profiles_df)]\n",
    "        if not valid_indices:\n",
    "             print(\"No valid indices found in FAISS search.\")\n",
    "             return []\n",
    "\n",
    "        search_results_df = comprehensive_product_profiles_df.iloc[valid_indices].copy()\n",
    "        search_results = search_results_df.to_dict('records')\n",
    "\n",
    "        print(f\"Found {len(search_results)} initial potential products from search.\")\n",
    "        return search_results\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during FAISS search: {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def search_for_information(state: PersonalShopperState) -> PersonalShopperState:\n",
    "    print(f\"Searching for informational answer for query: {state['input']}\")\n",
    "    query = state['input']\n",
    "    chat_history_str = format_chat_history_for_prompt(state.get('chat_history'))\n",
    "\n",
    "    global comprehensive_product_profiles_df\n",
    "\n",
    "    if comprehensive_product_profiles_df is None or comprehensive_product_profiles_df.empty :\n",
    "        print(\"Error: Comprehensive product profiles data not available for informational search.\")\n",
    "        new_state = state.copy()\n",
    "        new_state['informational_answer'] = \"Sorry, I can't access product information right now.\"\n",
    "        return new_state\n",
    "\n",
    "    query_keywords = query.lower().split()\n",
    "    relevant_snippets = []\n",
    "    max_snippets = 3\n",
    "\n",
    "    # Simple keyword search (can be improved with embedding-based semantic search on text fields too)\n",
    "    for idx, row in comprehensive_product_profiles_df.iterrows():\n",
    "        product_info = f\"{row.get('name','')} {row.get('description','')} {row.get('top_ingredients','')} {row.get('category','')}\".lower()\n",
    "        if any(keyword in product_info for keyword in query_keywords):\n",
    "            relevant_snippets.append(f\"- From product '{row.get('name','Unknown Product')}': {row.get('description','No description')[:150]}...\")\n",
    "            if len(relevant_snippets) >= max_snippets:\n",
    "                break\n",
    "    \n",
    "    if len(relevant_snippets) < max_snippets and 'Review' in comprehensive_product_profiles_df.columns:\n",
    "        # Filter reviews that mention any keyword\n",
    "        try:\n",
    "            # Ensure query_keywords are not empty and handle regex special characters\n",
    "            safe_keywords = [re.escape(kw) for kw in query_keywords if kw]\n",
    "            if safe_keywords:\n",
    "                relevant_reviews_df = comprehensive_product_profiles_df[\n",
    "                    comprehensive_product_profiles_df['Review'].str.lower().str.contains('|'.join(safe_keywords), na=False)\n",
    "                ]\n",
    "                for _, row in relevant_reviews_df.head(max_snippets - len(relevant_snippets)).iterrows():\n",
    "                    review_text = row['Review']\n",
    "                    # Attempt to find a snippet around a keyword\n",
    "                    found_snippet = review_text[:150] # Fallback to start of review\n",
    "                    for kw in query_keywords:\n",
    "                        if kw in review_text.lower():\n",
    "                            match = re.search(r'(?i).{0,70}' + re.escape(kw) + r'.{0,70}', review_text)\n",
    "                            if match:\n",
    "                                found_snippet = match.group(0)\n",
    "                                break\n",
    "                    relevant_snippets.append(f\"- From review for '{row.get('name','Unknown Product')}': \\\"...{found_snippet}...\\\"\")\n",
    "        except Exception as e_review_search:\n",
    "            print(f\"Error during review search: {e_review_search}\")\n",
    "\n",
    "\n",
    "    informational_answer = \"I couldn't find specific information related to your query in our product data or reviews.\"\n",
    "    if relevant_snippets:\n",
    "        snippets_text = \"\\n\".join(relevant_snippets)\n",
    "        answer_prompt = f\"\"\"{chat_history_str}\n",
    "\n",
    "You are a helpful and friendly salesperson for EverGlow Labs.\n",
    "The customer's LATEST query is: \"{query}\"\n",
    "Based on this query and the conversation history, use the following relevant information snippets from our product data and customer reviews to provide a concise and helpful answer.\n",
    "Cite the source of the information if appropriate (e.g., \"From product...\", \"A review mentions...\").\n",
    "\n",
    "Relevant Information:\n",
    "{snippets_text}\n",
    "\n",
    "Answer:\"\"\"\n",
    "        try:\n",
    "            response = llm.invoke(answer_prompt)\n",
    "            informational_answer = response.content.strip()\n",
    "            print(f\"Generated informational answer:\\n{informational_answer}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating informational answer with LLM: {e}\")\n",
    "            informational_answer = \"Sorry, I found some information but couldn't formulate a perfect answer right now.\"\n",
    "    else:\n",
    "        print(\"No relevant snippets found for informational query.\")\n",
    "\n",
    "    new_state = state.copy()\n",
    "    new_state['informational_answer'] = informational_answer\n",
    "    new_state.update({'recommended_products': None, 'clarification_questions': None, 'follow_up_question': None})\n",
    "    return new_state\n",
    "\n",
    "\n",
    "def recommend_products_based_on_search(state: PersonalShopperState) -> PersonalShopperState:\n",
    "    print(\"Attempting to recommend products based on identified categories and tags.\")\n",
    "    identified_categories = state.get('identified_categories', [])\n",
    "    identified_tags = state.get('identified_tags', [])\n",
    "    chat_history_str = format_chat_history_for_prompt(state.get('chat_history'))\n",
    "    user_input = state['input']\n",
    "\n",
    "\n",
    "    global comprehensive_product_profiles_df\n",
    "    new_state = state.copy()\n",
    "    new_state.update({'clarification_questions': None, 'informational_answer': None, 'follow_up_question': None})\n",
    "\n",
    "\n",
    "    if comprehensive_product_profiles_df is None or comprehensive_product_profiles_df.empty:\n",
    "        print(\"Error: Product data not available for recommendation.\")\n",
    "        new_state['recommended_products'] = [{\"name\": \"Sorry\", \"justification\": \"Product data is currently unavailable.\"}]\n",
    "        return new_state\n",
    "\n",
    "    filtered_df = comprehensive_product_profiles_df.copy()\n",
    "\n",
    "    if not identified_categories and not identified_tags:\n",
    "        print(\"No categories or tags identified. Cannot recommend based on strict filtering. Consider if this path should lead to clarification.\")\n",
    "        # This path might indicate a logic flaw if 'good' or 'keyword' input led here without identified terms.\n",
    "        # For now, providing a generic message. Or, one could try a broader embedding search.\n",
    "        # Let's try a general FAISS search based on the input if no categories/tags\n",
    "        print(f\"Performing a general FAISS search for: {user_input}\")\n",
    "        search_results_direct = search_products_with_index(user_input, top_k=3)\n",
    "        if search_results_direct:\n",
    "             filtered_df = pd.DataFrame(search_results_direct)\n",
    "             print(f\"Found {len(filtered_df)} products via direct FAISS search as fallback.\")\n",
    "        else:\n",
    "            new_state['recommended_products'] = [{\"name\": \"Sorry\", \"justification\": \"I couldn't find specific products based on your request. Could you try rephrasing or adding more details?\"}]\n",
    "            return new_state\n",
    "    else:\n",
    "        if identified_categories:\n",
    "            print(f\"Strictly filtering by categories: {identified_categories}\")\n",
    "            filtered_df = filtered_df[filtered_df['category'].isin(identified_categories)]\n",
    "        else: # No categories identified, but maybe tags were. If neither, previous block handles.\n",
    "            if not identified_tags: # Should not happen if the above \"if not identified_categories and not identified_tags\" is hit\n",
    "                print(\"No categories identified by LLM step. Cannot strictly filter by category.\")\n",
    "                # This implies the graph logic from identify_categories_and_tags should have gone to 'ask_clarification'\n",
    "                # However, if it reaches here, it means a 'good' or 'keyword' input didn't yield categories.\n",
    "                # A fallback: If no categories but input was 'good', do a general search.\n",
    "                if state.get('input_type') in ['good', 'keyword']: # Fallback for good/keyword inputs if no category found\n",
    "                    print(f\"Fallback: Performing general FAISS search for '{user_input}' as no categories were strictly identified but input type suggested recommendation.\")\n",
    "                    search_results_fallback = search_products_with_index(user_input, top_k=3)\n",
    "                    if search_results_fallback:\n",
    "                        filtered_df = pd.DataFrame(search_results_fallback)\n",
    "                    else:\n",
    "                        new_state['recommended_products'] = [{\"name\": \"Sorry\", \"justification\": \"Could not identify a relevant product category or find matches for your request.\"}]\n",
    "                        return new_state\n",
    "                else: # Should ideally be handled by graph routing to clarification\n",
    "                    new_state['recommended_products'] = [{\"name\": \"Sorry\", \"justification\": \"Could not identify a relevant product category from your request.\"}]\n",
    "                    return new_state\n",
    "        \n",
    "        if identified_tags and not filtered_df.empty:\n",
    "            print(f\"Filtering by tags: {identified_tags}\")\n",
    "            try:\n",
    "                # Handle potential NaN in 'tags' column and ensure it's string\n",
    "                valid_tags_series = filtered_df['tags'].fillna('').astype(str).str.lower()\n",
    "                # Create a boolean mask\n",
    "                mask = valid_tags_series.apply(lambda x_tags: any(tag.lower() in x_tags for tag in identified_tags))\n",
    "                filtered_df = filtered_df[mask]\n",
    "            except Exception as e_tag_filter:\n",
    "                print(f\"Error during tag filtering: {e_tag_filter}\")\n",
    "\n",
    "\n",
    "    if filtered_df.empty:\n",
    "        justification_text = \"Could not find products matching your specific criteria.\"\n",
    "        if identified_categories and identified_tags:\n",
    "             justification_text = f\"Could not find products matching categories ({', '.join(identified_categories)}) and tags ({', '.join(identified_tags)}).\"\n",
    "        elif identified_categories:\n",
    "             justification_text = f\"Could not find products for category ({', '.join(identified_categories)}) with the specified tags.\"\n",
    "        elif identified_tags:\n",
    "             justification_text = f\"Could not find products with tags ({', '.join(identified_tags)}) in the initially considered categories.\"\n",
    "\n",
    "        new_state['recommended_products'] = [{\"name\": \"Sorry\", \"justification\": justification_text}]\n",
    "        return new_state\n",
    "\n",
    "    # --- Ranking by Margin (if available) and selecting top 3 ---\n",
    "    if 'margin' in filtered_df.columns:\n",
    "        # Ensure margin is numeric, coercing errors to NaN, then fill NaN with a low value (e.g., 0 or -1) for sorting\n",
    "        filtered_df['margin'] = pd.to_numeric(filtered_df['margin'], errors='coerce').fillna(0)\n",
    "        recommended_products_df = filtered_df.sort_values(by='margin', ascending=False).head(3)\n",
    "    else:\n",
    "        recommended_products_df = filtered_df.head(3)\n",
    "\n",
    "    recommended_products_output = []\n",
    "    if not recommended_products_df.empty:\n",
    "        for _, row in recommended_products_df.iterrows():\n",
    "            justification_prompt = f\"\"\"{chat_history_str}\n",
    "\n",
    "You are a helpful and friendly salesperson for EverGlow Labs.\n",
    "The customer's LATEST query was: \"{user_input}\"\n",
    "We are recommending the product: \"{row.get('name', 'N/A')}\"\n",
    "Product Details:\n",
    "- Category: {row.get('category', 'N/A')}\n",
    "- Description: {row.get('description', 'N/A')[:150]}...\n",
    "- Key Ingredients: {row.get('top_ingredients', 'N/A')}\n",
    "- Tags: {row.get('tags', 'N/A')}\n",
    "\n",
    "Based on the conversation and product details, provide a *very short* (10-20 words) justification for this recommendation. Highlight a key benefit.\n",
    "Justification:\n",
    "\"\"\"\n",
    "            justification = \"This product is a great choice from EverGlow Labs, aligning with your needs.\" # Fallback\n",
    "            try:\n",
    "                response = llm.invoke(justification_prompt)\n",
    "                justification = response.content.strip()\n",
    "                # Ensure justification is short\n",
    "                justification = ' '.join(justification.split()[:20]) + ('...' if len(justification.split()) > 20 else '')\n",
    "            except Exception as e:\n",
    "                print(f\"Error generating justification for {row.get('name', 'N/A')}: {e}\")\n",
    "\n",
    "            recommended_products_output.append({\n",
    "                \"name\": row.get('name', 'N/A'),\n",
    "                \"justification\": justification,\n",
    "                \"category\": row.get('category', 'N/A'),\n",
    "                \"price\": row.get('price', 'N/A'), # Ensure 'price' column exists and is formatted\n",
    "                \"description_snippet\": row.get('description', '')[:100] + \"...\"\n",
    "            })\n",
    "    else: # Should be covered by earlier empty check, but as a safeguard\n",
    "        new_state['recommended_products'] = [{\"name\": \"Sorry\", \"justification\": \"I found some potential products but couldn't finalize recommendations.\"}]\n",
    "        return new_state\n",
    "\n",
    "    new_state['recommended_products'] = recommended_products_output\n",
    "\n",
    "    # --- Follow-up question logic (simplified based on whether tags were fully utilized) ---\n",
    "    # If categories were ID'd, but either no tags were ID'd OR ID'd tags didn't narrow down much from category.\n",
    "    if new_state.get('identified_categories') and not new_state.get('identified_tags') and recommended_products_output:\n",
    "        cat_list_str = \", \".join(new_state['identified_categories'])\n",
    "        follow_up_q_prompt = f\"\"\"{chat_history_str}\n",
    "\n",
    "You are a helpful and friendly salesperson for EverGlow Labs.\n",
    "The customer was interested in products from the category: {cat_list_str}. You've just recommended some.\n",
    "To further refine or confirm their choice, ask a brief, open-ended follow-up question that invites them to share more about their specific needs or preferences for these {cat_list_str} (e.g., specific skin concerns like hydration, anti-aging, texture preferences, etc., if not already clear).\n",
    "Keep it concise (1 sentence).\n",
    "\n",
    "Follow-up Question:\n",
    "\"\"\"\n",
    "        try:\n",
    "            response = llm.invoke(follow_up_q_prompt)\n",
    "            new_state['follow_up_question'] = response.content.strip()\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating follow-up question: {e}\")\n",
    "            new_state['follow_up_question'] = f\"Is there anything specific you're looking for in a {cat_list_str.lower()} (like texture or a particular benefit)?\"\n",
    "\n",
    "    return new_state\n",
    "\n",
    "\n",
    "# --- Graph Definition ---\n",
    "workflow = StateGraph(PersonalShopperState)\n",
    "\n",
    "workflow.add_node(\"check_input\", check_input_type)\n",
    "workflow.add_node(\"identify_categories_and_tags\", identify_categories_and_tags_json)\n",
    "workflow.add_node(\"ask_clarification\", ask_clarification_questions)\n",
    "workflow.add_node(\"search_information\", search_for_information)\n",
    "workflow.add_node(\"recommend_products\", recommend_products_based_on_search)\n",
    "\n",
    "workflow.set_entry_point(\"check_input\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"check_input\",\n",
    "    lambda state: state['input_type'],\n",
    "    {\n",
    "        \"informational\": \"search_information\",\n",
    "        \"vague\": \"ask_clarification\", # If vague, always ask clarification first\n",
    "        \"keyword\": \"identify_categories_and_tags\", # For keyword, try to identify first\n",
    "        \"good\": \"identify_categories_and_tags\",    # For good, try to identify first\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"identify_categories_and_tags\",\n",
    "    # If categories AND/OR tags are identified, try to recommend.\n",
    "    # If NEITHER are identified (even after this step for 'keyword'/'good' inputs), then ask for clarification.\n",
    "    lambda state: \"recommend_products\" if (state.get('identified_categories') or state.get('identified_tags')) else \"ask_clarification\",\n",
    "    {\n",
    "        \"recommend_products\": \"recommend_products\",\n",
    "        \"ask_clarification\": \"ask_clarification\",\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"ask_clarification\", END)\n",
    "workflow.add_edge(\"search_information\", END)\n",
    "workflow.add_edge(\"recommend_products\", END) # Follow-up is handled within the node if needed\n",
    "\n",
    "app = workflow.compile()\n",
    "\n",
    "# --- Main Agent Function (Updated for Chat History) ---\n",
    "def agent_main(user_query: str, current_chat_history: List[Dict[str, str]] | None = None):\n",
    "    if current_chat_history is None:\n",
    "        current_chat_history = []\n",
    "\n",
    "    # The agent's internal state will use this combined history for the current turn\n",
    "    turn_chat_history = current_chat_history + [{\"role\": \"user\", \"content\": user_query}]\n",
    "\n",
    "    initial_state_params = {\n",
    "        \"input\": user_query,\n",
    "        \"chat_history\": turn_chat_history, # Pass the history including the latest user query\n",
    "        \"input_type\": None,\n",
    "        \"clarification_questions\": None,\n",
    "        \"clarification_answers\": None, # This would be populated if user answers questions in a multi-turn vague flow\n",
    "        \"recommended_products\": None,\n",
    "        \"follow_up_question\": None,\n",
    "        \"informational_answer\": None,\n",
    "        \"identified_categories\": None,\n",
    "        \"identified_tags\": None\n",
    "    }\n",
    "\n",
    "    # Invoke the graph\n",
    "    final_state = app.invoke(initial_state_params)\n",
    "\n",
    "    # Construct a single text response from the agent's actions\n",
    "    assistant_response_parts = []\n",
    "    if final_state.get('informational_answer'):\n",
    "        assistant_response_parts.append(final_state['informational_answer'])\n",
    "    \n",
    "    if final_state.get('clarification_questions'):\n",
    "        # assistant_response_parts.append(\"I have a couple of questions to help you better:\")\n",
    "        for q_idx, q_text in enumerate(final_state['clarification_questions']):\n",
    "            assistant_response_parts.append(f\"{q_text}\") # Present questions directly\n",
    "            \n",
    "    if final_state.get('recommended_products'):\n",
    "        if not (len(final_state['recommended_products']) == 1 and final_state['recommended_products'][0].get('name', '').lower() == \"sorry\"):\n",
    "            assistant_response_parts.append(\"\\nHere are some products I recommend:\")\n",
    "            for prod in final_state['recommended_products']:\n",
    "                recommendation = f\"- **{prod.get('name', 'N/A')}**\"\n",
    "                if 'justification' in prod and prod['justification']:\n",
    "                    recommendation += f\": {prod['justification']}\"\n",
    "                \n",
    "                details = []\n",
    "                if 'category' in prod and prod.get('category'):\n",
    "                    details.append(f\"Category: {prod['category']}\")\n",
    "                if 'price' in prod and prod.get('price') is not None:\n",
    "                    try:\n",
    "                        details.append(f\"Price: ${float(prod['price']):.2f}\")\n",
    "                    except (ValueError, TypeError):\n",
    "                        details.append(f\"Price: {prod['price']}\") # Keep as is if not convertible\n",
    "                if details:\n",
    "                    recommendation += f\" ({', '.join(details)})\"\n",
    "                assistant_response_parts.append(recommendation)\n",
    "        else: # It's a \"Sorry\" message\n",
    "            assistant_response_parts.append(final_state['recommended_products'][0].get('justification', \"Sorry, I couldn't find a suitable product.\"))\n",
    "\n",
    "    if final_state.get('follow_up_question'):\n",
    "        # Add a newline if there were recommendations before the follow-up\n",
    "        if final_state.get('recommended_products') and not (len(final_state['recommended_products']) == 1 and final_state['recommended_products'][0].get('name', '').lower() == \"sorry\"):\n",
    "            assistant_response_parts.append(f\"\\n{final_state['follow_up_question']}\")\n",
    "        else:\n",
    "            assistant_response_parts.append(final_state['follow_up_question'])\n",
    "\n",
    "\n",
    "    if not assistant_response_parts:\n",
    "        # This case should ideally be rare if graph logic is sound and nodes always produce some output or error.\n",
    "        # Check input type to provide a more relevant default response.\n",
    "        input_type = final_state.get('input_type', 'unknown')\n",
    "        if input_type == 'vague' and not final_state.get('clarification_questions'):\n",
    "             assistant_response_parts.append(\"I understand. To help you best, could you please tell me a bit more about your specific skin concerns or what kind of product you're looking for?\")\n",
    "        elif input_type == 'informational' and not final_state.get('informational_answer'):\n",
    "             assistant_response_parts.append(\"I'm sorry, I couldn't find the specific information you're looking for right now.\")\n",
    "        elif final_state.get('recommended_products') is None and input_type in ['good', 'keyword']: # No recs, no sorry message\n",
    "            assistant_response_parts.append(\"I'm having a bit of trouble finding products for that right now. Could you try a different search?\")\n",
    "        else:\n",
    "             assistant_response_parts.append(\"I'm not quite sure how to help with that. Could you please rephrase or provide more details?\")\n",
    "\n",
    "\n",
    "    assistant_response_str = \"\\n\".join(filter(None,assistant_response_parts)).strip()\n",
    "\n",
    "\n",
    "    # Append assistant's response to history for the next turn\n",
    "    # This is the history that should be passed to the next call of agent_main\n",
    "    updated_full_chat_history = turn_chat_history + [{\"role\": \"assistant\", \"content\": assistant_response_str}]\n",
    "\n",
    "    return {\n",
    "        'assistant_response': assistant_response_str,\n",
    "        'chat_history': updated_full_chat_history,\n",
    "        'clarification_questions': final_state.get('clarification_questions'),\n",
    "        'recommended_products': final_state.get('recommended_products'),\n",
    "        'follow_up_question': final_state.get('follow_up_question'),\n",
    "        'informational_answer': final_state.get('informational_answer'),\n",
    "        'input_type': final_state.get('input_type')\n",
    "    }\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # --- Example Usage of the Chat Agent ---\n",
    "    print(\"Personal Shopper Agent Initialized. Type 'exit' to end.\")\n",
    "    chat_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b316e78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with some example queries:\n",
    "    # Queries for testing different paths:\n",
    "    # 1. Vague -> Clarification\n",
    "    # query1 = \"I need something for my skin\"\n",
    "    # 2. Informational -> Search Info\n",
    "    # query2 = \"what is vitamin c good for?\"\n",
    "    # 3. Keyword -> Identify -> Recommend (-> Follow-up if only category was ID'd)\n",
    "    # query3 = \"show me a serum\"\n",
    "    # 4. Good -> Identify -> Recommend\n",
    "    # query4 = \"I want a hydrating moisturizer for dry skin\"\n",
    "    # 5. No categories/tags found after identification (should go to clarification)\n",
    "    # query5 = \"I want something for xyzabc concern\" (assuming xyzabc is not a known tag/cat)\n",
    "    # 6. Query that should find products\n",
    "    # query6 = \"exfoliating cleanser\"\n",
    "\n",
    "    # # Example chat flow:\n",
    "    # queries = [\n",
    "    #     \"Hi there!\", # General greeting, might be classified as vague or good\n",
    "    #     \"I'm looking for a new serum.\", # Keyword\n",
    "    #     \"Something for anti-aging.\", # Could be an answer to a clarification, or a new query with tags\n",
    "    #     \"What are the benefits of retinol?\", # Informational\n",
    "    #     \"Okay, show me a retinol serum for sensitive skin then.\", # Good query\n",
    "    #     \"Thanks!\"\n",
    "    # ]\n",
    "\n",
    "    # for q in queries:\n",
    "    #     print(f\"\\nUser: {q}\")\n",
    "    #     if q.lower() == 'exit':\n",
    "    #         break\n",
    "        \n",
    "    #     response_data = agent_main(q, chat_history)\n",
    "        \n",
    "    #     print(f\"Assistant:\\n{response_data['assistant_response']}\")\n",
    "    #     chat_history = response_data['chat_history'] # Persist history for the next turn\n",
    "        \n",
    "    #     print(\"\\n--- Current State Details (for debugging) ---\")\n",
    "    #     print(f\"Input Type: {response_data.get('input_type')}\")\n",
    "    #     if response_data.get('clarification_questions'):\n",
    "    #         print(f\"Clarification Questions: {response_data['clarification_questions']}\")\n",
    "    #     if response_data.get('recommended_products'):\n",
    "    #         print(f\"Recommended Products: {response_data['recommended_products']}\")\n",
    "    #     if response_data.get('follow_up_question'):\n",
    "    #         print(f\"Follow-up Question: {response_data['follow_up_question']}\")\n",
    "    #     if response_data.get('informational_answer'):\n",
    "    #         print(f\"Informational Answer: {response_data['informational_answer']}\")\n",
    "    #     print(\"--------------------------------------------\")\n",
    "    #     time.sleep(30)\n",
    "\n",
    "    # Interactive loop:\n",
    "    # while True:\n",
    "    #     user_input = input(\"You: \")\n",
    "    #     if user_input.lower() == 'exit':\n",
    "    #         print(\"Assistant: Goodbye!\")\n",
    "    #         break\n",
    "        \n",
    "    #     response_data = agent_main(user_input, chat_history)\n",
    "        \n",
    "    #     print(f\"Assistant:\\n{response_data['assistant_response']}\")\n",
    "    #     chat_history = response_data['chat_history']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shop_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
